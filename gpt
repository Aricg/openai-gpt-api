#!/usr/bin/env python

import openai
import sys
import argparse
import os
import configparser
import subprocess
from tempfile import NamedTemporaryFile

home_dir = os.path.expanduser("~")
dotfile_path = os.path.join(home_dir, '.openai_config')

config = configparser.ConfigParser()
if os.path.exists(dotfile_path):
    config.read(dotfile_path)
else:
    print("config file required at ~/.openai_config")
    exit(1)

openai.api_key = config['DEFAULT']['API_KEY']

commands = {
    "git_commit": ['git', 'status', '-v'],
    # Add more commands here
}

prompts = {
    "commit_message_prompt": "Given the changes in the provided Git diff, generate a commit message following the Conventional Commits specification. \
    The commit message should start with a type, optionally followed by a scope, and then a concise summary in the imperative mood of the changes made. \
    If necessary, follow this with a more detailed explanation of what changes were made and why in the body section. \
    Remember to keep the summary under 50 characters and the body under 100 characters per line if included.\n",
    "one_shot": "ask me questions about what you think the following code is doing until you feel like you know what i'm trying to do, \
    then help me accomplish what it looks like i'm trying to do. Do you understand?",
    # Add more prompts here
}

def get_input_or_file_input():
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--file", help="Provide a filename to use as input")
    group.add_argument("--command-output", choices=list(commands.keys()), help="Choose a command to run and use its output")
    parser.add_argument("--model", help="model to use for the chat completion", default=config['DEFAULT']['MODEL'])
    parser.add_argument("--temperature", help="temperature to use for the chat completion", default=config['DEFAULT']['TEMPERATURE'], type=float)
    args = parser.parse_args()

    if args.file:
        with open(args.file, "r") as file:
            content = file.read()
    else:  # command output
        content = subprocess.check_output(commands[args.command_output]).decode()

    return content, args

def select_prompt():
    prompt_names = list(prompts.keys())
    print("Select a prompt:")
    for i, name in enumerate(prompt_names):
        print(f"{i}. {name}")
    selection = int(input("Enter the number of your selection: "))
    return prompts[prompt_names[selection]]

def edit_message_in_vim(message):
    with NamedTemporaryFile(suffix=".tmp") as tf:
        tf.write(message.encode())
        tf.flush()
        subprocess.call(["lvim", tf.name])
        tf.seek(0)
        edited_message = tf.read().decode()
    return edited_message

def main():
    content, args = get_input_or_file_input()
    prompt = select_prompt()

    delimeter = "```\n"
    message_content = prompt + delimeter + content + delimeter

    print("\nHere is the message to be sent:\n")
    print("\n#######################################################################\n")
    print(message_content)
    print("\n#######################################################################\n")

    confirm = input("\nDo you want to send this message? [y/n/edit]: ")
    if confirm.lower() == 'edit':
        message_content = edit_message_in_vim(message_content)
        confirm = input("\nDo you want to send this message? [y/n]: ")

    if confirm.lower() != 'y':
        print("Operation cancelled.")
        sys.exit()

    while True:
        chat_completion = openai.ChatCompletion.create(
            model=args.model, 
            messages=[{"role": "user", "content": message_content}],
            temperature=args.temperature
        )
        print(chat_completion.choices[0].message.content)  # type: ignore

        satisfied = input("\nAre you happy with the response? \"No\" to resend with gpt4 [y/n]: ")
        if satisfied.lower() == 'y':
            break
        else:
            print("Resending the request with model 'gpt-4'.")
            args.model = 'gpt-4'

if __name__ == "__main__":
    main()

