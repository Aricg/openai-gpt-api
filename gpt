#!/usr/bin/env python

import openai
import sys
import argparse
import os
import configparser
import subprocess
from tempfile import NamedTemporaryFile

home_dir = os.path.expanduser("~")
dotfile_path = os.path.join(home_dir, '.openai_config')

config = configparser.ConfigParser()
if os.path.exists(dotfile_path):
    config.read(dotfile_path)
else:
    print("config file required at ~/.openai_config")
    exit(1)

openai.api_key = config['DEFAULT']['API_KEY']

commands = {
    "git_commit": ['git', 'status', '-v'],
    # Add more commands here
}

prompts = {
    "commit_message_prompt": "Given the changes in the provided Git diff, generate a commit message following the Conventional Commits specification....",
    # Add more prompts here
}

def get_input_or_file_input():
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--file", help="Provide a filename to use as input")
    group.add_argument("--command-output", choices=list(commands.keys()), help="Choose a command to run and use its output")
    parser.add_argument("--model", help="model to use for the chat completion", default=config['DEFAULT']['MODEL'])
    parser.add_argument("--temperature", help="temperature to use for the chat completion", default=config['DEFAULT']['TEMPERATURE'], type=float)
    args = parser.parse_args()

    if args.file:
        with open(args.file, "r") as file:
            content = file.read()
    else:  # command output
        content = subprocess.check_output(commands[args.command_output]).decode()

    return content, args

def select_prompt():
    prompt_names = list(prompts.keys())
    print("Select a prompt:")
    for i, name in enumerate(prompt_names):
        print(f"{i}. {name}")
    selection = int(input("Enter the number of your selection: "))
    return prompts[prompt_names[selection]]

def edit_message_in_vim(message):
    with NamedTemporaryFile(suffix=".tmp") as tf:
        tf.write(message.encode())
        tf.flush()
        subprocess.call(["vim", tf.name])
        tf.seek(0)
        edited_message = tf.read().decode()
    return edited_message

def main():
    content, args = get_input_or_file_input()
    prompt = select_prompt()

    message_content = prompt + content

    print("\nHere is the message to be sent:\n")
    print("\n#######################################################################\n")
    print(message_content)
    print("\n#######################################################################\n")

    confirm = input("\nDo you want to send this message? [y/n/edit]: ")
    if confirm.lower() == 'edit':
        message_content = edit_message_in_vim(message_content)
        confirm = input("\nDo you want to send this message? [y/n]: ")

    if confirm.lower() != 'y':
        print("Operation cancelled.")
        sys.exit()

    while True:
        chat_completion = openai.ChatCompletion.create(
            model=args.model, 
            messages=[{"role": "user", "content": message_content}],
            temperature=args.temperature
        )
        print(chat_completion.choices[0].message.content)  # type: ignore

        satisfied = input("\nAre you happy with the response? \"No\" to resend with gpt4 [y/n]: ")
        if satisfied.lower() == 'y':
            break
        else:
            print("Resending the request with model 'gpt-4'.")
            args.model = 'gpt-4'

if __name__ == "__main__":
    main()

